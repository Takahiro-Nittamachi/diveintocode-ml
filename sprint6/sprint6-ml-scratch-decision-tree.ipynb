{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.この課題の目的\n",
    "スクラッチを通して決定木を理解する\n",
    "複雑なアルゴリズムの実装に慣れる\n",
    "以下の要件をすべて満たしていた場合、合格とします。\n",
    "\n",
    "※Jupyter Notebookを使い課題に沿った検証や説明ができている。\n",
    "\n",
    "# 2.スクラッチによる実装\n",
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "決定木は分類と回帰双方に使用できますが、分類のみを扱います。\n",
    "\n",
    "必須課題としては空間の分割を1回だけ行う、深さ1の決定木を作成します。それよりも深い決定木の作成はアドバンス課題とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】ジニ不純度を求める関数\n",
    "まずは空間を分割するための指標値、ジニ不純度を計算する関数を作成してください。ノード$t$に対するジニ不純度$I(t)$\n",
    " は以下の数式で求まります。\n",
    " $$\n",
    " I(t) = 1-\\sum_{i=1}^{K}P^2(C_i|t) = 1-\\sum_{i=1}^{K}(\\frac{N_{t,i}}{N_{t,all}})^{2}\n",
    " $$\n",
    " \n",
    " $t$ : ノードのインデックス\n",
    "\n",
    "$i$ : クラスのインデックス\n",
    "\n",
    "$K$ : クラスの数\n",
    "\n",
    "$C_i$ : i番目のクラス\n",
    "\n",
    "$P(C_i|t)$ :　t番目のノードにおける$C_i$の割合\n",
    "\n",
    "$N_t,i$ : t番目のノードのi番目のクラスに属するサンプル数\n",
    "\n",
    "$N_t,all$ : t番目のノードのサンプルの総数\n",
    "\n",
    "まずは簡単な例を作り、手計算と関数の結果を比較してください。\n",
    "\n",
    "例\n",
    "- クラス1:サンプル数15, クラス2:サンプル数15 → ジニ不純度0.500\n",
    "- クラス1:サンプル数15, クラス2:サンプル数15, クラス3:サンプル数15 → ジニ不純度0.667\n",
    "- クラス1:サンプル数18, クラス2:サンプル数12 → ジニ不純度0.480\n",
    "- クラス1:サンプル数30, クラス2:サンプル数0 → ジニ不純度0.000\n",
    "この他にもいくつか試してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス作成時に使用するクラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ま前処理に使用するクラス\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ScratchDecesionTreeClassifierクラス内で使用するクラス\n",
    "from statistics import mode\n",
    "from collections import Counter\n",
    "\n",
    "# 評価指標のクラス\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 決定領域を描画する際に使用するクラス\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備(シンプルデータセット1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】ジニ不純度を求める関数\n",
    "まずは空間を分割するための指標値、ジニ不純度を計算する関数を作成してください。ノード$t$に対するジニ不純度$I(t)$\n",
    " は以下の数式で求まります。\n",
    " $$\n",
    " I(t) = 1-\\sum_{i=1}^{K}P^2(C_i|t) = 1-\\sum_{i=1}^{K}(\\frac{N_{t,i}}{N_{t,all}})^{2}\n",
    " $$\n",
    " \n",
    " $t$ : ノードのインデックス\n",
    "\n",
    "$i$ : クラスのインデックス\n",
    "\n",
    "$K$ : クラスの数\n",
    "\n",
    "$C_i$ : i番目のクラス\n",
    "\n",
    "$P(C_i|t) :　t番目のノードにおける$C_i$の割合\n",
    "\n",
    "$N_t,i$ : t番目のノードのi番目のクラスに属するサンプル数\n",
    "\n",
    "$N_t,all$ : t番目のノードのサンプルの総数\n",
    "\n",
    "まずは簡単な例を作り、手計算と関数の結果を比較してください。\n",
    "\n",
    "例\n",
    "- クラス1:サンプル数15, クラス2:サンプル数15 → ジニ不純度0.500\n",
    "- クラス1:サンプル数15, クラス2:サンプル数15, クラス3:サンプル数15 → ジニ不純度0.667\n",
    "- クラス1:サンプル数18, クラス2:サンプル数12 → ジニ不純度0.480\n",
    "- クラス1:サンプル数30, クラス2:サンプル数0 → ジニ不純度0.000\n",
    "この他にもいくつか試してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute_gini_impurityメソッド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gini_impurity(y):\n",
    "    \"\"\"\n",
    "    ジニ不純度を計算\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : 次の形のndarray, shape(n_samples, 1)\n",
    "        正解データ(分類ラベルのデータが格納)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gini_impurity : float\n",
    "        ジニ不純度\n",
    "    \"\"\"\n",
    "\n",
    "    # 正解データの合計を取得\n",
    "    y_count = len(y)\n",
    "\n",
    "    # 正解データから各ラベルを取得\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    # ジニ不純度の初期値 1で設定\n",
    "    gini_impurity = 1\n",
    "\n",
    "    # 総和計算の結果を格納する変数(for文の中で計算結果を加算し続ける)\n",
    "    total = 0\n",
    "\n",
    "    # データの個数が0か判別\n",
    "    if y_count == 0:\n",
    "\n",
    "        # 0の場合→gini_impurity=０とする\n",
    "        gini_impurity = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        # 0ではない場合　→　ジニ不純度を計算\n",
    "        for _class in classes:\n",
    "\n",
    "            # 各ラベルのそれぞれの個数を取得\n",
    "            class_count = len(y[y == _class])\n",
    "\n",
    "            # 総和計算を実施　→　total = total  + Σ（各ラベルの個数　/ ラベルの総数） ^2 \n",
    "            total = total + (class_count / y_count)**2\n",
    "\n",
    "        # ジニ不純度の計算 (１ −　Σ（各ラベルの個数　/ ラベルの総数） ^2 )\n",
    "        gini_impurity = 1 - total\n",
    "\n",
    "        return gini_impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス1:サンプル数15, クラス2:サンプル数15 → ジニ不純度0.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 15, 2: 15})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gini_impurity(test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス1:サンプル数15, クラス2:サンプル数15, クラス3:サンプル数15 → ジニ不純度0.667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr2 = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 15, 2: 15, 3: 15})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gini_impurity(test_arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス1:サンプル数18, クラス2:サンプル数12 → ジニ不純度0.480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr3 = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 18, 2: 12})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gini_impurity(test_arr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス1:サンプル数30, クラス2:サンプル数0 → ジニ不純度0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr4 = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 30})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_arr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gini_impurity(test_arr4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】情報利得を求める関数\n",
    "次に、情報利得を計算する関数を作成してください。先ほど作成したジニ不純度 $I(t)$を計算する関数を呼び出して使います。情報利得$IG$は以下の数式で求まります。\n",
    "$$\n",
    "IG(p) = I(p)-\\frac{N_{left,all}}{N_{p,all}}I(left)-\\frac{N_{right,all}}{N_{p,all}}I(right)\n",
    "$$\n",
    "\n",
    "$p$ : 親ノードを示すインデックス\n",
    "\n",
    "$left$ : 左側のノードを示すインデックス\n",
    "\n",
    "$right$ : 右側のノードを示すインデックス\n",
    "\n",
    "まずは簡単な例を作り、手計算と関数の結果を比較してください。\n",
    "\n",
    "例\n",
    "\n",
    "- 左ノードクラス1:サンプル数10, 左ノードクラス2:サンプル数30, 右ノードクラス1:サンプル数20, 右ノードクラス2:サンプル数5 → 情報利得0.143\n",
    "\n",
    "この他にもいくつか試してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Information_gain(parent, left, right):\n",
    "    \"\"\"\n",
    "    情報利得を計算\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent : 次の形のndarray, shape(n_samples, feature)\n",
    "        特徴量データ\n",
    "\n",
    "    left : 次の形のndarray, shape(左側のノードのサンプル数, feature)\n",
    "        左側のノードのデータ\n",
    "\n",
    "    right : 次の形のndarray, shape(右側のノードのサンプル数, feature)\n",
    "        右側のノードのデータ    \n",
    "    Returns\n",
    "    -------\n",
    "    information_gain : 次の形のndarray, shape (ラベル数, 1)\n",
    "        各ラベル毎のジニ不純度\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ジニ不純度の計算\n",
    "    \"\"\"\n",
    "\n",
    "    # 親ノードのジニ不純度の計算\n",
    "    parent_gini = compute_gini_impurity(parent)\n",
    "\n",
    "    # 左側のノードのジニ不純度の計算\n",
    "    group1_gini = compute_gini_impurity(left)\n",
    "\n",
    "    # 右側のノードのジニ不純度の計算\n",
    "    group2_gini = compute_gini_impurity(right)\n",
    "\n",
    "    \"\"\"\n",
    "    各データの個数を取得\n",
    "    \"\"\"\n",
    "    # 親ノードのデータの個数\n",
    "    parent_count = len(parent)\n",
    "\n",
    "    # 左側のノードのデータの個数\n",
    "    left_count = len(left)\n",
    "\n",
    "    # 右側のノードのデータの個数\n",
    "    right_count = len(right)\n",
    "\n",
    "    \"\"\"\n",
    "    情報利得の計算\n",
    "    \"\"\"\n",
    "    information_gain = parent_gini - ((left_count / parent_count) * group1_gini) \\\n",
    "                                    - ((right_count / parent_count) * group2_gini)\n",
    "\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 左ノードクラス1:サンプル数10, 左ノードクラス2:サンプル数30, 右ノードクラス1:サンプル数20, 右ノードクラス2:サンプル数5 → 情報利得0.143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_node = np.array([1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\\\n",
    "                        1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 30, 2: 35})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(parent_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_node = np.array([1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 10, 2: 30})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(left_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_node = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 20, 2: 5})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(right_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14319526627218937"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_Information_gain(parent_node, left_node, right_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】深さ1の決定木分類器クラスの作成\n",
    "深さが1の決定機分類器のクラスを作成し、Sprint2で作成した分類のパイプラインに組み込んでください。\n",
    "\n",
    "クラスの基本構造はSprint3の線形回帰を参考にし、名前は<font color=\"Red\">ScratchDecesionTreeClassifier</font>としてください。\n",
    "\n",
    "メソッドやパラメータなどはscikit-learnを参考にしてください。\n",
    "\n",
    "[sklearn.tree.DecisionTreeClassifier — scikit-learn 0.20.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "検証段階ではJupyter Notebook上で書いていき、最終的にはpyファイルにモジュールとしてまとめてください。\n",
    "\n",
    "深さ1とは空間の分割を1回だけ行うことを指します。\n",
    "\n",
    "<u>決定木のアルゴリズム</u>\n",
    "\n",
    "ある特徴量の軸に対して、全てのパターンのしきい値を考え、それぞれの情報利得を計算していきます。各点の値をしきい値にする方法が一般的です。（ただし、実際にはしきい値の数は点の数よりひとつ少なくて良いことになります）分割の全候補の中で最も情報利得が大きくなるものをそのノードの分割方法として採用します。\n",
    "\n",
    "ジニ不純度が0になるノード、または指定された深さのノードは葉と呼ばれます。葉にはそれぞれ推定時にどのクラスに分類するかを記録しておきます。ジニ不純度が0でない場合は、多数決により分類するクラスを決定します。\n",
    "\n",
    "<u>ヒント</u>\n",
    "\n",
    "これまでのスクラッチ課題に比べてアルゴリズムが複雑です。コードを書く前に、フローチャートなどで整理するようにしましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifier():\n",
    "    \"\"\"\n",
    "    決定木のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.classes_ : 次の形のndarray, shape (n_features,)\n",
    "        クラスラベルのデータ\n",
    "    self.n_classes_ : 次の形のndarray, shape (self.iter,)\n",
    "        ラベル数\n",
    "    self.current_threshold_index : tuple\n",
    "        閾値のindex\n",
    "    self.current_threshold_value : float\n",
    "        閾値\n",
    "    self.n_sample_ : int\n",
    "        サンプルデータの数(データの行数)\n",
    "    self.n_feature_ : int\n",
    "        特徴量の数(データの列数)\n",
    "    self.self.group1_index_ : list\n",
    "        クラス1に分類した特徴量のindexが格納するリスト\n",
    "    self.self.group2_index_ : list\n",
    "        クラス2に分類した特徴量のindexが格納するリスト\n",
    "    self.current_infomation_gain : float\n",
    "        情報利得\n",
    "    self.group1_gini = None : int\n",
    "        グループ1のジニ不純度\n",
    "    self.group2_gini = None : int\n",
    "        グループ2のジニ不純度\n",
    "    self.group1_majority : int\n",
    "        グループ1の分類結果(学習の際に多数決で決まる)\n",
    "    self.group2_majority : int\n",
    "        グループ2の分類結果(学習の際に多数決で決まる)\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classes_ = None\n",
    "        self.n_classes_ = None\n",
    "        self.current_threshold_index_ = None\n",
    "        self.current_threshold_value_ = None\n",
    "        self.n_sample_ = None\n",
    "        self.n_feature_ = None\n",
    "        self.group1_index_ = None\n",
    "        self.group2_index_ = None\n",
    "        self.current_infomation_gain_ = None\n",
    "        self.group1_gini_ = None\n",
    "        self.group2_gini_ = None\n",
    "        self.group1_majority_ = None\n",
    "        self.group2_majority_ = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        深さが1の決定木分類機の最適な閾値を決める\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        \"\"\"\n",
    "        # 入力データの前処理\n",
    "        \n",
    "        # 入力データをnumpy配列に変換 →　dataframeが入力された場合も対応可能とする\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # 1次元の場合は、２次元に変換\n",
    "        if X.ndim == 1:\n",
    "            X = X[:, np.newaxis]\n",
    "            \n",
    "        # 最適な閾値を求める\n",
    "        self.disitribute(X, y)\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        入力データを２値分類する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # 予測値を計算(学習にて求めた最適な閾値を使用し、値が大きいか小さいかで入力データを分類する)\n",
    "        # どの特徴量を使用するかは、閾値のindexを使用し、入力データから比較すべき特徴量列を抽出(X[:, self.current_threshold_index[1]の箇所)\n",
    "        return np.where(X[:, self.current_threshold_index_[1]] > self.current_threshold_value_, self.group1_majority_, self.group2_majority_)\n",
    "                \n",
    "\n",
    "    def disitribute(self, X, y):\n",
    "        \"\"\"\n",
    "        入力データから分類を行う為の最適な閾値を求める\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, 1)\n",
    "\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        # 特徴量の行数を設定\n",
    "        self.n_sample_ = len(X)\n",
    "        \n",
    "        # 特徴量の列数を設定\n",
    "        self.n_feature_ = X.shape[1]\n",
    "        \n",
    "        # 情報利得の初期設定\n",
    "        self.current_infomation_gain_ = 0\n",
    "        \n",
    "        # ジニ不純度の初期設定\n",
    "        parent_gini = 0\n",
    "        group1_gini = 0\n",
    "        group2_gini = 0\n",
    "        \n",
    "        # 分類したサンプルのindexを格納するshape(0, 2)の空のnumpy配列を作成\n",
    "        self.group1_index_ = []\n",
    "        self.group2_index_ = []\n",
    "\n",
    "        \"\"\"\n",
    "        閾値により分類開始\n",
    "        \"\"\"\n",
    "        # 入力Xの列数までカウントアップ　→　比較する閾値の列方向のindexとなる\n",
    "        for threshold_column in range(self.n_feature_):\n",
    "\n",
    "            \n",
    "            # 入力Xの行数までカウントアップ　→　比較する閾値の行方向のindexとなる\n",
    "            for threshold_line in range(self.n_sample_):\n",
    "\n",
    "                # 仮で設定した閾値の設定\n",
    "                test_threshold_index = (threshold_line, threshold_column)\n",
    "                self.group1_index_ = []\n",
    "                self.group2_index_ = []\n",
    "                \n",
    "                # 入力Xの行数までカウントアップ　→　forが回るたびに1つindexの値を参照するようになる\n",
    "                for comparison_line in range(self.n_sample_):\n",
    "\n",
    "                    # 値を比較するデータのindex\n",
    "                    comparison_index = (comparison_line, threshold_column)\n",
    "\n",
    "                    # 仮で設定した閾値と値を比較\n",
    "                    if X[comparison_index] > X[test_threshold_index]:\n",
    "                        \n",
    "                        # 閾値より値が高い→group1と判断しindexを格納\n",
    "                        self.group1_index_.append(comparison_index[0])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # 閾値より値が低い→group2と判断しindexを格納\n",
    "                        self.group2_index_.append(comparison_index[0])\n",
    "\n",
    "                \"\"\"\n",
    "                情報利得を比較\n",
    "                \"\"\"\n",
    "                \n",
    "                # 情報利得を計算\n",
    "                test_infomation_gain = self.compute_Information_gain(y, y[self.group1_index_], y[self.group2_index_])\n",
    "\n",
    "                # 現状で最も高い情報利得と値を比較\n",
    "                if test_infomation_gain > self.current_infomation_gain_:\n",
    "                    # 値が大きい　→　閾値、情報利得の値、閾値のindexを更新\n",
    "                    self.current_infomation_gain_ = test_infomation_gain\n",
    "                    self.current_threshold_index_ = test_threshold_index\n",
    "                    self.current_threshold_value_ = X[self.current_threshold_index_]\n",
    "\n",
    "                    # 各分類結果の多数決のクラスを取得\n",
    "                    self.group1_majority_ = mode(y[self.group1_index_])\n",
    "                    self.group2_majority_ = mode(y[self.group2_index_])\n",
    "    \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def compute_gini_impurity(self,y):\n",
    "        \"\"\"\n",
    "        ジニ不純度を計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape(n_samples, 1)\n",
    "            正解データ(分類ラベルのデータが格納)\n",
    "        \n",
    "        label : ラベルのデータ型に準拠\n",
    "            ジニ不純度を求めたいラベル(Noneであれば親ノードのジニ不純度を計算)\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        gini_impurity : float\n",
    "            ジニ不純度\n",
    "        \"\"\"\n",
    "    \n",
    "        # 正解データの合計を取得\n",
    "        y_count = len(y)\n",
    "    \n",
    "        # 正解データから各ラベルを取得\n",
    "        classes = np.unique(y)\n",
    "    \n",
    "        # ジニ不純度を初期値 1で設定\n",
    "        gini_impurity = 1\n",
    "    \n",
    "        # 総和計算の結果を格納する変数(for文の中で計算結果を加算し続ける)\n",
    "        total = 0\n",
    "        \n",
    "        # データの個数が0か判別\n",
    "        if y_count == 0:\n",
    "            \n",
    "            # 0の場合→gini_impurity=０とする\n",
    "            gini_impurity = 0\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # 0ではない場合　→　gini_impurityを計算\n",
    "            for _class in classes:\n",
    "\n",
    "                # 各ラベルのそれぞれの個数を取得\n",
    "                class_count = len(y[y == _class])\n",
    "\n",
    "                # 総和計算を実施　→　total = total  + Σ（各ラベルの個数　/ ラベルの総数） ^2 \n",
    "                total = total + (class_count / y_count)**2\n",
    "\n",
    "            # ジニ不純度の計算 (１ −　Σ（各ラベルの個数　/ ラベルの総数） ^2 )\n",
    "            gini_impurity = 1 - total\n",
    "\n",
    "            return gini_impurity\n",
    "    \n",
    "    \n",
    "    def compute_Information_gain(self,parent, left, right):\n",
    "        \"\"\"\n",
    "        情報利得を計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        parent : 次の形のndarray, shape(n_samples, feature)\n",
    "            親ノードのデータ\n",
    "        left : 次の形のndarray, shape(左側のノードのサンプル数, feature)\n",
    "            左側のノードのデータ\n",
    "        right : 次の形のndarray, shape(右側のノードのサンプル数, feature)\n",
    "            右側のノードのデータ    \n",
    "        Returns\n",
    "        -------\n",
    "        information_gain : 次の形のndarray, shape (ラベル数, 1)\n",
    "            各ラベル毎の情報利得\n",
    "        \"\"\"\n",
    "    \n",
    "        \"\"\"\n",
    "        ジニ不純度の計算\n",
    "        \"\"\"\n",
    "    \n",
    "        # 親ノードのジニ不純度の計算\n",
    "        parent_gini = self.compute_gini_impurity(parent)\n",
    "    \n",
    "        # 左側のノードのジニ不純度の計算\n",
    "        self.group1_gini = self.compute_gini_impurity(left)\n",
    "    \n",
    "        # 右側のノードのジニ不純度の計算\n",
    "        self.group2_gini = self.compute_gini_impurity(right)\n",
    "        \n",
    "        \"\"\"\n",
    "        各データの個数を取得\n",
    "        \"\"\"\n",
    "        # 親ノードのデータの個数\n",
    "        parent_count = len(parent)\n",
    "\n",
    "        # 左側のノードのデータの個数\n",
    "        left_count = len(left)\n",
    "\n",
    "        # 右側のノードのデータの個数\n",
    "        right_count = len(right)\n",
    "        \n",
    "        # ジニ不純度がゼロとなったら(どちらか片方のグループに全ての特徴量が分類されたら)情報利得をゼロとする\n",
    "        if left_count == 0 or right_count == 0:\n",
    "            return 0\n",
    "\n",
    "        \"\"\"\n",
    "        情報利得の計算\n",
    "        \"\"\"\n",
    "        information_gain = parent_gini - ((left_count / parent_count) * self.group1_gini) \\\n",
    "                                        - ((right_count / parent_count) * self.group2_gini)\n",
    "\n",
    "        return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = ScratchDecesionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】指標値の算出\n",
    "分類に関する指標値で精度を確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score = {}\\n'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Score , Recall Score , F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 1', 'class -1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.92      0.92      0.92        53\n",
      "    class -1       0.91      0.91      0.91        47\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       100\n",
      "   macro avg       0.92      0.92      0.92       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】決定領域の可視化\n",
    "2値分類のデータセットに対して決定領域を可視化してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 今回は2クラスの分類の為、2種類のマーカと色を用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ('s', 'x')\n",
    "cmap = ListedColormap(('red', 'blue'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの最小値と最大値を確認し、メッシュデータを0.01刻みで作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min, x1_max = X_test[:, 0].min()-1, X_test[:, 0].max()+1\n",
    "x2_min, x2_max = X_test[:, 1].min()-1, X_test[:, 1].max()+1\n",
    "x1_mesh, x2_mesh = np.meshgrid(np.arange(x1_min, x1_max, 0.01),\n",
    "                                   np.arange(x2_min, x2_max, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メッシュデータに対して作成したモデルで分類を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = cls.predict(np.array([x1_mesh.ravel(), x2_mesh.ravel()]).T)\n",
    "z = z.reshape(x1_mesh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定領域を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.contourf(x1_mesh, x2_mesh, z, alpha=0.4, cmap=cmap)\n",
    "plt.xlim(x1_mesh.min(), x1_mesh.max())\n",
    "plt.ylim(x2_mesh.min(), x2_mesh.max())\n",
    "\n",
    "for idx, cl in enumerate(np.unique(y_test)):\n",
    "    plt.scatter(x=X_test[y_test == cl, 0],\n",
    "                y=X_test[y_test == cl, 1],\n",
    "                alpha=0.6,\n",
    "                c=cmap(idx),\n",
    "                edgecolors='black',\n",
    "                marker=markers[idx],\n",
    "                label=cl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】決定木の利用場面\n",
    "最終発表時に以下の内容についてディスカッションを行います。自分なりの意見を用意しておいてください。\n",
    "\n",
    "決定木が他の手法に比べて有効だと考えられるのはどういった場面か\n",
    "注意点\n",
    "\n",
    "答えがある問いではありません。いろいろな視点から見て理解を深めていきましょう。\n",
    "\n",
    "## ①機械学習についてあまり詳しくない人に分類のアルゴリズムを説明する場面\n",
    "### そのように考えた理由→分類アルゴリズムが理解しやすい為\n",
    "- 決定木の分類アルゴリズムは各特徴量の値と比較し大きいか小さいかで分類を行うという、他の分類アルゴリズム(ロジスティック回帰、SVM等)より、比較的理解しやすいアルゴリズムの為、業務等であまり機械学習に詳しくない人に分類アルゴリズムを説明する際に有効であると考えられる。\n",
    "\n",
    "## ②視覚的にどのようなルールで分類されているのかを確認したい時\n",
    "- scikit-learnのtreeクラスのgraphvizメソッドを使用することで決定木の表示ができ、この表示から視覚的にどのように分類されているのかを確認できる。この事は①と同様に機械学習に詳しくない人に対して分類アルゴリズムを説明する際に有効な手段であると考えられる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
