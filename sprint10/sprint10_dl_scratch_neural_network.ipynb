{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6hS09JJ3YOf"
   },
   "source": [
    "## 使用クラスのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XjmISsT3YOk"
   },
   "source": [
    "# 1.この課題の目的\n",
    "スクラッチを通してニューラルネットワークの基礎を理解する\n",
    "画像データの簡単な扱い方を知る\n",
    "以下の要件をすべて満たしていた場合、合格とします。\n",
    "\n",
    "※Jupyter Notebookを使い課題に沿った検証や説明ができている。\n",
    "\n",
    "# 2.スクラッチによる実装\n",
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "今回は多クラス分類を行う3層のニューラルネットワークを作成します。層の数などは固定した上でニューラルネットワークの基本を確認しましょう。次のSprintで層を自由に変えられる設計にしていきます。\n",
    "\n",
    "データセットの用意\n",
    "MNISTデータセットを使用します。以下のコードを実行すればKerasによりデータセットをダウンロードし、展開まで行えます。\n",
    "\n",
    "データセットをダウンロードするコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REFPayTm3YOl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62g-aTKg3YOo"
   },
   "source": [
    "## MNISTとは？\n",
    "\n",
    "画像分類のための定番データセットで、手書き数字認識を行います。このデータセットには学習用6万枚、テスト用1万枚の28×28ピクセルの白黒画像、およびそれらが0〜9のどの数字であるかが含まれています。\n",
    "\n",
    "## 画像データとは？\n",
    "\n",
    "デジタル画像は点の集合で、これをピクセルと呼びます。一般的に白黒画像であればピクセルには0〜255の値が含まれます。一方、カラー画像であればR（赤）、G（緑）、B（青）それぞれに対応する0〜255の値が含まれます。機械学習をする上では、この0〜255の値一つひとつが特徴量として扱われます。0〜255は符号なしの8ビット整数で表せる範囲になるため、NumPyであれば「uint8」型の変数として保持できます。\n",
    "\n",
    "データセットの確認\n",
    "まず、どういったデータなのかを見てみます。\n",
    "\n",
    "## サンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "id": "Pakufoso3YOo",
    "outputId": "7f2ea452-83fd-45b8-cc1b-9a96610ee4cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OKAOwlnH3YOr",
    "outputId": "cb2f0080-0557-4d84-8d4d-7414283dc94d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzjMevX53YOt"
   },
   "source": [
    "# 3.平滑化\n",
    "(1, 28, 28)の各画像を、(1, 784)に変換します。これまで学んできた機械学習手法や、今回扱う全結合層のみのニューラルネットワークではこの形で扱います。全てのピクセルが一列になっていることを、平滑化（flatten）してあるという風に表現します。\n",
    "\n",
    "## サンプルコード\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAaGcX5T3YOt"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rS-08S4L3YOv"
   },
   "source": [
    "## 補足\n",
    "\n",
    "ここまで機械学習を学んでくる中で、特徴量の数を「次元」と呼んできました。その視点ではMNISTは784次元のデータです。一方で、NumPyのshapeが(784,)の状態を1次元配列とも呼びます。画像としての縦横の情報を持つ（28, 28)の状態であれば、2次元配列です。この視点では2次元のデータです。さらに、もしもカラー画像であれば(28, 28, 3)ということになり、3次元配列です。先ほどの視点では3次元のデータになります。しかし、白黒でもカラーでも平面画像であり、立体データではないという視点で、2次元のデータです。画像データを扱う際にはこのように「次元」という言葉が複数の意味合いで使われることに注意してください。\n",
    "\n",
    "## 画像データの可視化\n",
    "画像データを可視化します。plt.imshowに渡します。\n",
    "\n",
    "サンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "siy3JGQ53YOv",
    "outputId": "49aa9d99-6d09-42ea-e709-0cc01cb9fbfb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {:.4f}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UtS1Ckwy3YOx"
   },
   "source": [
    "## 前処理\n",
    "画像は0から255のuint8型で表されますが、機械学習をする上では0から1のfloat型で扱うことになります。色は理想的には連続値であり、それを特徴量とするからです。以下のコードで変換可能です。\n",
    "\n",
    "## サンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Oj8I9O9_3YOy",
    "outputId": "26ed3ad6-77d8-4155-9da6-fe01fc6b759f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45s5wKG63YO0"
   },
   "source": [
    "また、正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際にはone-hot表現に変換します。scikit-learnのOneHotEncoderを使用したコードが以下です。このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います。\n",
    "\n",
    "## サンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "d3SmFzAl3YO1",
    "outputId": "51be7738-9d57-4d50-a162-b36deb7c7f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xi_5iDMk3YO3",
    "outputId": "db53c3f8-a0db-4ec4-8c1e-7c084bea1def"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xcB4p8Bz3YO5",
    "outputId": "0a60ee21-d10b-449e-c5b1-92d3916f90c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D66EO43Q3YO7"
   },
   "source": [
    "[sklearn.preprocessing.OneHotEncoder — scikit-learn 0.20.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "さらに、学習用データ6万枚の内2割を検証用データとして分割してください。学習用データが48000枚、検証用データが12000枚となります。\n",
    "\n",
    "## サンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xiqvMHCa3YO7",
    "outputId": "035d6d18-0d01-4f83-96a7-373be1812d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3co3CY-Q3YO-"
   },
   "source": [
    "# 【問題1】ニューラルネットワーク分類器のクラスを作成\n",
    "ニューラルネットワーク分類器のクラスScratchSimpleNeuralNetrowkClassifierを作成してください。\n",
    "\n",
    "以下が雛形です。基本的な構成は機械学習編の線形回帰やロジスティック回帰などと同様です。\n",
    "\n",
    "雛形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtJOldY_3YO_"
   },
   "source": [
    "## フォワードプロパゲーション\n",
    "三層のニューラルネットワークのフォワードプロパゲーションを作成します。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_6_nYDS3YPA"
   },
   "source": [
    "```python\n",
    "batch_size = 10 # バッチサイズ\n",
    "n_features = 784 # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecOhmTN93YPC"
   },
   "source": [
    "「1層目」\n",
    "\n",
    "$A_1 = X \\cdot W_1 + B_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ta_T4CM-3YPC"
   },
   "source": [
    "### GetMiniBatchクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZCOiNQH3YPD"
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3DjqRM_3YPF"
   },
   "source": [
    "### ScratchSimpleNeuralNetrowkClassifierクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self.lr = lr # 学習率\n",
    "    self.sigma = sigma # ガウス分布の標準偏差\n",
    "    self.batch_size = batch_size # バッチサイズ\n",
    "    self.n_features = n_features # 特徴量の数\n",
    "    self.n_nodes1 = n_nodes1 # 1層目のノード数\n",
    "    self.n_nodes2 = n_nodes2 # 2層目のノード数\n",
    "    self.n_output = n_output # 出力のクラス数（3層目のノード数）\n",
    "    self.verbose = verbose　# 学習結果を表示するかを設定するフラグ\n",
    "\n",
    "    # 損失を記録する配列を用意\n",
    "    self.loss = []\n",
    "    self.val_loss = []\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.w1_ = self.sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
    "    self.w2_ = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "    self.w3_ = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "\n",
    "    self.b1_ = self.sigma * np.random.randn(1, self.n_nodes1)\n",
    "    self.b2_ = self.sigma * np.random.randn(1, self.n_nodes2)\n",
    "    self.b3_ = self.sigma * np.random.randn(1, self.n_output)\n",
    "\n",
    "    self.Z1_ = None\n",
    "    self.Z2_ = None\n",
    "    self.Z3_ = None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,lr, sigma, batch_size, n_epochs, n_features, n_nodes1, n_nodes2, n_output,\\\n",
    "                         activation, verbose=None):\n",
    "        self.lr = lr # 学習率\n",
    "        self.sigma = sigma # ガウス分布の標準偏差\n",
    "        self.batch_size = batch_size # バッチサイズ\n",
    "        self.n_epochs = n_epochs # エポック数\n",
    "        self.n_features = n_features # 特徴量の数\n",
    "        self.n_nodes1 = n_nodes1 # 1層目のノード数\n",
    "        self.n_nodes2 = n_nodes2 # 2層目のノード数\n",
    "        self.n_output = n_output # 出力のクラス数（3層目のノード数）\n",
    "        self.activation = activation # 活性化関数を指定する文字列\n",
    "        self.verbose = verbose# 学習結果を表示するかを設定するフラグ\n",
    "\n",
    "        \n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "        self.verification_flag = None\n",
    "\n",
    "        \"\"\"\n",
    "        重みとバイアスの初期化\n",
    "        \"\"\"\n",
    "        self.w1_ = self.sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
    "        self.w2_ = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        self.w3_ = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "\n",
    "        self.b1_ = self.sigma * np.random.randn(1, self.n_nodes1)\n",
    "        self.b2_ = self.sigma * np.random.randn(1, self.n_nodes2)\n",
    "        self.b3_ = self.sigma * np.random.randn(1, self.n_output)\n",
    "        \n",
    "        self.Z1_ = None\n",
    "        self.Z2_ = None\n",
    "        self.Z3_ = None\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        # 検証データの有無を記録するフラグ\n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.verification_flag = True\n",
    "        \n",
    "\n",
    "                \n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "        \n",
    "        if self.verification_flag:\n",
    "            y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "        \n",
    "#         X_train, y_train, X_val, y_val = self.prepro(X_train, y_train,\\\n",
    "#                                                                                  X_val, y_val)\n",
    "     \n",
    "        \n",
    "        \"\"\"\n",
    "        ミニバッチ処理開始\n",
    "        \"\"\"\n",
    "        #ミニバッチ処理を行うインスタンスを作成\n",
    "\n",
    "        for e in range(self.n_epochs):\n",
    "            num = 0\n",
    "            get_mini_batch_train = GetMiniBatch(X_train, y_train_one_hot, batch_size=self.batch_size)\n",
    "            \n",
    "            # バッチサイズ毎にデータを取得する\n",
    "            for mini_X_train, mini_y_train in get_mini_batch_train:\n",
    "                num += 1\n",
    "\n",
    "                # 順伝搬\n",
    "                z_n1, a_n1, z_n2, a_n2, z_out, a_out = self.forward_prop(mini_X_train)\n",
    "#                 print('z_out = {:.4f}'.format(np.mean(z_out)))\n",
    "#                 print('a_out = {:.4f}'.format(np.mean(a_out)))\n",
    "                \n",
    "                #　逆伝搬+パラメータ更新\n",
    "                self.back_prop(mini_X_train, mini_y_train, z_n1, a_n1, z_n2, a_n2, z_out, a_out)\n",
    "            \n",
    "\n",
    "#                 _, _, _, _, _, a_out = self.forward_prop(mini_X_train)\n",
    "#                 loss = self.cross_entropy_error(mini_y_train, a_out)\n",
    "#                 print('学習中のloss = {:.4f}'.format(loss))\n",
    "\n",
    "            # 順伝搬\n",
    "            _, _, _, _, _, a_out = self.forward_prop(X_train)\n",
    "            loss1 = self.cross_entropy_error(y_train_one_hot, a_out)\n",
    "            self.loss.append(loss1)\n",
    "#             print('loss1 = {:.4f}'.format(loss1))\n",
    "\n",
    "            # 検証用データの有無を判別→データが存在する場合、フラグを変更\n",
    "            if self.verification_flag:\n",
    "                _, _, _, _, _, a_out = self.forward_prop(X_val)\n",
    "                loss2 = self.cross_entropy_error(y_val_one_hot, a_out)\n",
    "                self.val_loss.append(loss2)\n",
    "\n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程などを出力する\n",
    "                print('{}epoch目\\n'.format(e + 1))\n",
    "                print('学習用正解データとの誤差　：　{:.4f}\\n'.format(loss1))\n",
    "\n",
    "                if self.verification_flag:\n",
    "                    print('検証用正解データとの誤差　：　{:.4f}\\n'.format(loss2))\n",
    "                print('------------------------------------------------')\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "        # 順伝搬\n",
    "        _, _, _, _, _, a_out = self.forward_prop(X_test)\n",
    "        \n",
    "        # ソフトマックス関数の出力値(入力データがそれぞれの値である確率)から\n",
    "        # 最も高い値を格納しているインデックス(0 ~ 9)を行単位(axis=1)で取り出す\n",
    "        return np.argmax(a_out, axis=1)\n",
    "\n",
    "    \n",
    "    # 順伝搬\n",
    "    def forward_prop(self, X):\n",
    "\n",
    "        # 隠れ層(第1層)\n",
    "        z_n1 = X @ self.w1_ + self.b1_\n",
    "        # シグモイド関数で計算\n",
    "        a_n1 = self.activation_func(z_n1)\n",
    "\n",
    "        # 隠れ層(第２層)\n",
    "        z_n2= a_n1 @ self.w2_ + self.b2_\n",
    "        # ハイパボリックタンジェント関数で計算\n",
    "        a_n2 = self.activation_func(z_n2)\n",
    "\n",
    "        # 出力層(第３層)\n",
    "        z_out = a_n2 @ self.w3_ + self.b3_\n",
    "        a_out = self.softmax(z_out)\n",
    "        \n",
    "        return z_n1, a_n1, z_n2, a_n2, z_out, a_out\n",
    "    \n",
    "    \n",
    "    # 誤差逆伝搬\n",
    "    def back_prop(self,X , y, z_n1, a_n1, z_n2, a_n2, z_out, a_out):\n",
    "        \n",
    "        # 出力層(第3層)\n",
    "        # ΔL/ΔA3の計算\n",
    "        \n",
    "        grad_z_out =  a_out - y\n",
    "        grad_b_out = grad_z_out.sum(axis=0)\n",
    "        grad_w_out = a_n2.T @ grad_z_out\n",
    "\n",
    "        # 重みの更新\n",
    "        self.w3_ -= self.lr * (grad_w_out / self.batch_size)\n",
    "        self.b3_ -= self.lr * (grad_b_out / self.batch_size)\n",
    "#         print('self.w3_ = {:.4f}'.format(self.w3_))\n",
    "#         print('self.b3_ = {:.4f}'.format(self.b3_))\n",
    "        \n",
    "        # (隠れ層)第２層\n",
    "        # ΔL/ΔA2の計算\n",
    "        grad_a_n2 =  (grad_z_out @ self.w3_.T) \n",
    "#         print('grad_a_n2 = {:.4f} self.derivative_func(z_n2) = {:.4f}'.format(grad_a_n2, self.derivative_func(z_n2)))\n",
    "        grad_z_n2 = grad_a_n2 * self.derivative_func(a_n2)\n",
    "\n",
    "        grad_b_n2 = grad_z_n2.sum(axis=0)\n",
    "        grad_w_n2 = a_n1.T @ grad_z_n2\n",
    "\n",
    "                \n",
    "        # 重みの更新\n",
    "        self.w2_ -=  self.lr * (grad_w_n2 /self.batch_size)\n",
    "        # バイアスの更新\n",
    "        self.b2_ -= self.lr * (grad_b_n2 / self.batch_size)\n",
    "\n",
    "        \n",
    "        # (隠れ層)第1層\n",
    "        grad_a_n1 = grad_z_n2 @ self.w2_.T\n",
    "        grad_z_n1 = grad_a_n1 * self.derivative_func(a_n1)\n",
    "        grad_b_n1 = grad_z_n1.sum(axis=0)\n",
    "        grad_w_n1 = X.T @ grad_z_n1\n",
    "\n",
    "        # バイアスの更新\n",
    "        self.w1_ -= self.lr * (grad_w_n1 / self.batch_size)\n",
    "        self.b1_ -= self.lr * (grad_b_n1 / self.batch_size)\n",
    "\n",
    "    \n",
    "    def activation_func(self, A):\n",
    "        \n",
    "        \"\"\"\n",
    "        指定の活性化関数で順伝搬する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "        # オーバーフロー対策の為、eの乗数の最大値、最小値を設定\n",
    "#         sigmoid_range = 34.538776394910684\n",
    "#         A = np.clip(A, -sigmoid_range, sigmoid_range)\n",
    "        \n",
    "        # funcの値を確認\n",
    "        # 0の場合→シグモイド関数を計算\n",
    "        if self.activation == 'sig':\n",
    "            # シグモイド関数を計算\n",
    "            return 1.0 / (1.0 + np.exp(-A))\n",
    "        \n",
    "        # 1の場合→ハイポリックタンジェント関数を計算\n",
    "        elif self.activation == 'tan':\n",
    "            return np.tanh(A)\n",
    "\n",
    "    \n",
    "    def derivative_func(self, dZ):\n",
    "        \n",
    "        \"\"\"\n",
    "        指定の活性化関数で逆伝搬する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        # funcの値を確認\n",
    "        # 0の場合→シグモイド関数を計算\n",
    "        if self.activation == 'sig':\n",
    "            # シグモイド関数を計算\n",
    "            return (dZ * (1.0 - dZ))\n",
    "        \n",
    "        # 1の場合→ハイポリックタンジェント関数を計算\n",
    "        elif self.activation == 'tan':\n",
    "            return (1. - (np.tanh(dZ))**2)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def softmax(self, A3):\n",
    "        \n",
    "        # 最大値を取得\n",
    "        A3_max = np.max(A3, axis=1)\n",
    "        \n",
    "        # オーバーフロー対策の為、各値から最大値を引く\n",
    "        exp_A = np.exp(A3 - A3_max.reshape(-1, 1))\n",
    "        sum_exp_A = np.sum(exp_A, axis=1).reshape(-1, 1)\n",
    "\n",
    "        # ソフトマックス関数を計算\n",
    "        return exp_A / sum_exp_A\n",
    "    \n",
    "    \n",
    "    def cross_entropy_error(self, t, y ):\n",
    "#         # 計算結果がマイナス無限大となるのを防ぐ為に微小な値を作成\n",
    "#         delta = 1e-7\n",
    "        \n",
    "#         # クロスエントロピー誤差を計算\n",
    "#         return (- (np.sum(t * np.log(y + delta))))\n",
    "        value1 = t * (np.log(y + 1e-05)) # ゼロ除算対策\n",
    "#         value2 = (1. - t) * np.log(1. - y + 1e-05) # ゼロ除算対策\n",
    "        train_cost = -np.sum(value1)\n",
    "        return train_cost /t.shape[0]\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        plt.plot(range(self.n_epochs), self.loss, label='loss')\n",
    "        plt.plot(range(self.n_epochs), self.val_loss, label='val_loss')\n",
    "        plt.xlabel('repeat_count')\n",
    "        plt.ylabel('mse')\n",
    "        plt.title('Learning curve')\n",
    "        plt.legend()\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　2.3111\n",
      "\n",
      "検証用正解データとの誤差　：　2.3122\n",
      "\n",
      "------------------------------------------------\n",
      "2epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　2.3155\n",
      "\n",
      "検証用正解データとの誤差　：　2.3175\n",
      "\n",
      "------------------------------------------------\n",
      "3epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　2.3182\n",
      "\n",
      "検証用正解データとの誤差　：　2.3210\n",
      "\n",
      "------------------------------------------------\n",
      "4epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　2.2063\n",
      "\n",
      "検証用正解データとの誤差　：　2.2104\n",
      "\n",
      "------------------------------------------------\n",
      "5epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　1.4580\n",
      "\n",
      "検証用正解データとの誤差　：　1.4635\n",
      "\n",
      "------------------------------------------------\n",
      "6epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　1.1273\n",
      "\n",
      "検証用正解データとの誤差　：　1.1252\n",
      "\n",
      "------------------------------------------------\n",
      "7epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.8526\n",
      "\n",
      "検証用正解データとの誤差　：　0.8460\n",
      "\n",
      "------------------------------------------------\n",
      "8epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.7207\n",
      "\n",
      "検証用正解データとの誤差　：　0.7142\n",
      "\n",
      "------------------------------------------------\n",
      "9epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.6485\n",
      "\n",
      "検証用正解データとの誤差　：　0.6409\n",
      "\n",
      "------------------------------------------------\n",
      "10epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.5835\n",
      "\n",
      "検証用正解データとの誤差　：　0.5743\n",
      "\n",
      "------------------------------------------------\n",
      "11epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.5320\n",
      "\n",
      "検証用正解データとの誤差　：　0.5223\n",
      "\n",
      "------------------------------------------------\n",
      "12epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.4925\n",
      "\n",
      "検証用正解データとの誤差　：　0.4836\n",
      "\n",
      "------------------------------------------------\n",
      "13epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.4562\n",
      "\n",
      "検証用正解データとの誤差　：　0.4487\n",
      "\n",
      "------------------------------------------------\n",
      "14epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.4198\n",
      "\n",
      "検証用正解データとの誤差　：　0.4136\n",
      "\n",
      "------------------------------------------------\n",
      "15epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.3876\n",
      "\n",
      "検証用正解データとの誤差　：　0.3824\n",
      "\n",
      "------------------------------------------------\n",
      "16epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.3635\n",
      "\n",
      "検証用正解データとの誤差　：　0.3592\n",
      "\n",
      "------------------------------------------------\n",
      "17epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.3457\n",
      "\n",
      "検証用正解データとの誤差　：　0.3423\n",
      "\n",
      "------------------------------------------------\n",
      "18epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.3317\n",
      "\n",
      "検証用正解データとの誤差　：　0.3291\n",
      "\n",
      "------------------------------------------------\n",
      "19epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.3199\n",
      "\n",
      "検証用正解データとの誤差　：　0.3181\n",
      "\n",
      "------------------------------------------------\n",
      "20epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.3093\n",
      "\n",
      "検証用正解データとの誤差　：　0.3085\n",
      "\n",
      "------------------------------------------------\n",
      "21epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2996\n",
      "\n",
      "検証用正解データとの誤差　：　0.2995\n",
      "\n",
      "------------------------------------------------\n",
      "22epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2902\n",
      "\n",
      "検証用正解データとの誤差　：　0.2910\n",
      "\n",
      "------------------------------------------------\n",
      "23epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2811\n",
      "\n",
      "検証用正解データとの誤差　：　0.2828\n",
      "\n",
      "------------------------------------------------\n",
      "24epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2722\n",
      "\n",
      "検証用正解データとの誤差　：　0.2747\n",
      "\n",
      "------------------------------------------------\n",
      "25epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2633\n",
      "\n",
      "検証用正解データとの誤差　：　0.2666\n",
      "\n",
      "------------------------------------------------\n",
      "26epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2544\n",
      "\n",
      "検証用正解データとの誤差　：　0.2586\n",
      "\n",
      "------------------------------------------------\n",
      "27epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2457\n",
      "\n",
      "検証用正解データとの誤差　：　0.2508\n",
      "\n",
      "------------------------------------------------\n",
      "28epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2372\n",
      "\n",
      "検証用正解データとの誤差　：　0.2431\n",
      "\n",
      "------------------------------------------------\n",
      "29epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2288\n",
      "\n",
      "検証用正解データとの誤差　：　0.2356\n",
      "\n",
      "------------------------------------------------\n",
      "30epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2208\n",
      "\n",
      "検証用正解データとの誤差　：　0.2283\n",
      "\n",
      "------------------------------------------------\n",
      "31epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2130\n",
      "\n",
      "検証用正解データとの誤差　：　0.2214\n",
      "\n",
      "------------------------------------------------\n",
      "32epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.2056\n",
      "\n",
      "検証用正解データとの誤差　：　0.2148\n",
      "\n",
      "------------------------------------------------\n",
      "33epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1987\n",
      "\n",
      "検証用正解データとの誤差　：　0.2086\n",
      "\n",
      "------------------------------------------------\n",
      "34epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1920\n",
      "\n",
      "検証用正解データとの誤差　：　0.2027\n",
      "\n",
      "------------------------------------------------\n",
      "35epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1858\n",
      "\n",
      "検証用正解データとの誤差　：　0.1972\n",
      "\n",
      "------------------------------------------------\n",
      "36epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1799\n",
      "\n",
      "検証用正解データとの誤差　：　0.1920\n",
      "\n",
      "------------------------------------------------\n",
      "37epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1744\n",
      "\n",
      "検証用正解データとの誤差　：　0.1871\n",
      "\n",
      "------------------------------------------------\n",
      "38epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1691\n",
      "\n",
      "検証用正解データとの誤差　：　0.1825\n",
      "\n",
      "------------------------------------------------\n",
      "39epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1642\n",
      "\n",
      "検証用正解データとの誤差　：　0.1782\n",
      "\n",
      "------------------------------------------------\n",
      "40epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1595\n",
      "\n",
      "検証用正解データとの誤差　：　0.1741\n",
      "\n",
      "------------------------------------------------\n",
      "41epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1550\n",
      "\n",
      "検証用正解データとの誤差　：　0.1703\n",
      "\n",
      "------------------------------------------------\n",
      "42epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1508\n",
      "\n",
      "検証用正解データとの誤差　：　0.1667\n",
      "\n",
      "------------------------------------------------\n",
      "43epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1468\n",
      "\n",
      "検証用正解データとの誤差　：　0.1633\n",
      "\n",
      "------------------------------------------------\n",
      "44epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1429\n",
      "\n",
      "検証用正解データとの誤差　：　0.1601\n",
      "\n",
      "------------------------------------------------\n",
      "45epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1393\n",
      "\n",
      "検証用正解データとの誤差　：　0.1570\n",
      "\n",
      "------------------------------------------------\n",
      "46epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1358\n",
      "\n",
      "検証用正解データとの誤差　：　0.1542\n",
      "\n",
      "------------------------------------------------\n",
      "47epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1324\n",
      "\n",
      "検証用正解データとの誤差　：　0.1514\n",
      "\n",
      "------------------------------------------------\n",
      "48epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1292\n",
      "\n",
      "検証用正解データとの誤差　：　0.1488\n",
      "\n",
      "------------------------------------------------\n",
      "49epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1261\n",
      "\n",
      "検証用正解データとの誤差　：　0.1464\n",
      "\n",
      "------------------------------------------------\n",
      "50epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1232\n",
      "\n",
      "検証用正解データとの誤差　：　0.1440\n",
      "\n",
      "------------------------------------------------\n",
      "51epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1203\n",
      "\n",
      "検証用正解データとの誤差　：　0.1418\n",
      "\n",
      "------------------------------------------------\n",
      "52epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1176\n",
      "\n",
      "検証用正解データとの誤差　：　0.1396\n",
      "\n",
      "------------------------------------------------\n",
      "53epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1150\n",
      "\n",
      "検証用正解データとの誤差　：　0.1376\n",
      "\n",
      "------------------------------------------------\n",
      "54epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1124\n",
      "\n",
      "検証用正解データとの誤差　：　0.1357\n",
      "\n",
      "------------------------------------------------\n",
      "55epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1100\n",
      "\n",
      "検証用正解データとの誤差　：　0.1338\n",
      "\n",
      "------------------------------------------------\n",
      "56epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1076\n",
      "\n",
      "検証用正解データとの誤差　：　0.1321\n",
      "\n",
      "------------------------------------------------\n",
      "57epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1053\n",
      "\n",
      "検証用正解データとの誤差　：　0.1304\n",
      "\n",
      "------------------------------------------------\n",
      "58epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1031\n",
      "\n",
      "検証用正解データとの誤差　：　0.1287\n",
      "\n",
      "------------------------------------------------\n",
      "59epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.1009\n",
      "\n",
      "検証用正解データとの誤差　：　0.1272\n",
      "\n",
      "------------------------------------------------\n",
      "60epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0988\n",
      "\n",
      "検証用正解データとの誤差　：　0.1257\n",
      "\n",
      "------------------------------------------------\n",
      "61epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0968\n",
      "\n",
      "検証用正解データとの誤差　：　0.1243\n",
      "\n",
      "------------------------------------------------\n",
      "62epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0949\n",
      "\n",
      "検証用正解データとの誤差　：　0.1229\n",
      "\n",
      "------------------------------------------------\n",
      "63epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0930\n",
      "\n",
      "検証用正解データとの誤差　：　0.1216\n",
      "\n",
      "------------------------------------------------\n",
      "64epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0911\n",
      "\n",
      "検証用正解データとの誤差　：　0.1204\n",
      "\n",
      "------------------------------------------------\n",
      "65epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0893\n",
      "\n",
      "検証用正解データとの誤差　：　0.1191\n",
      "\n",
      "------------------------------------------------\n",
      "66epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0876\n",
      "\n",
      "検証用正解データとの誤差　：　0.1180\n",
      "\n",
      "------------------------------------------------\n",
      "67epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0859\n",
      "\n",
      "検証用正解データとの誤差　：　0.1169\n",
      "\n",
      "------------------------------------------------\n",
      "68epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0842\n",
      "\n",
      "検証用正解データとの誤差　：　0.1158\n",
      "\n",
      "------------------------------------------------\n",
      "69epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0826\n",
      "\n",
      "検証用正解データとの誤差　：　0.1147\n",
      "\n",
      "------------------------------------------------\n",
      "70epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0810\n",
      "\n",
      "検証用正解データとの誤差　：　0.1137\n",
      "\n",
      "------------------------------------------------\n",
      "71epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0795\n",
      "\n",
      "検証用正解データとの誤差　：　0.1128\n",
      "\n",
      "------------------------------------------------\n",
      "72epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0780\n",
      "\n",
      "検証用正解データとの誤差　：　0.1118\n",
      "\n",
      "------------------------------------------------\n",
      "73epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0765\n",
      "\n",
      "検証用正解データとの誤差　：　0.1109\n",
      "\n",
      "------------------------------------------------\n",
      "74epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0751\n",
      "\n",
      "検証用正解データとの誤差　：　0.1100\n",
      "\n",
      "------------------------------------------------\n",
      "75epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0737\n",
      "\n",
      "検証用正解データとの誤差　：　0.1092\n",
      "\n",
      "------------------------------------------------\n",
      "76epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0724\n",
      "\n",
      "検証用正解データとの誤差　：　0.1084\n",
      "\n",
      "------------------------------------------------\n",
      "77epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0710\n",
      "\n",
      "検証用正解データとの誤差　：　0.1076\n",
      "\n",
      "------------------------------------------------\n",
      "78epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0697\n",
      "\n",
      "検証用正解データとの誤差　：　0.1068\n",
      "\n",
      "------------------------------------------------\n",
      "79epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0684\n",
      "\n",
      "検証用正解データとの誤差　：　0.1061\n",
      "\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0672\n",
      "\n",
      "検証用正解データとの誤差　：　0.1054\n",
      "\n",
      "------------------------------------------------\n",
      "81epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0660\n",
      "\n",
      "検証用正解データとの誤差　：　0.1047\n",
      "\n",
      "------------------------------------------------\n",
      "82epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0648\n",
      "\n",
      "検証用正解データとの誤差　：　0.1040\n",
      "\n",
      "------------------------------------------------\n",
      "83epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0636\n",
      "\n",
      "検証用正解データとの誤差　：　0.1033\n",
      "\n",
      "------------------------------------------------\n",
      "84epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0625\n",
      "\n",
      "検証用正解データとの誤差　：　0.1027\n",
      "\n",
      "------------------------------------------------\n",
      "85epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0613\n",
      "\n",
      "検証用正解データとの誤差　：　0.1021\n",
      "\n",
      "------------------------------------------------\n",
      "86epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0602\n",
      "\n",
      "検証用正解データとの誤差　：　0.1015\n",
      "\n",
      "------------------------------------------------\n",
      "87epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0592\n",
      "\n",
      "検証用正解データとの誤差　：　0.1009\n",
      "\n",
      "------------------------------------------------\n",
      "88epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0581\n",
      "\n",
      "検証用正解データとの誤差　：　0.1003\n",
      "\n",
      "------------------------------------------------\n",
      "89epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0571\n",
      "\n",
      "検証用正解データとの誤差　：　0.0998\n",
      "\n",
      "------------------------------------------------\n",
      "90epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0561\n",
      "\n",
      "検証用正解データとの誤差　：　0.0993\n",
      "\n",
      "------------------------------------------------\n",
      "91epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0551\n",
      "\n",
      "検証用正解データとの誤差　：　0.0988\n",
      "\n",
      "------------------------------------------------\n",
      "92epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0541\n",
      "\n",
      "検証用正解データとの誤差　：　0.0983\n",
      "\n",
      "------------------------------------------------\n",
      "93epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0531\n",
      "\n",
      "検証用正解データとの誤差　：　0.0978\n",
      "\n",
      "------------------------------------------------\n",
      "94epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0522\n",
      "\n",
      "検証用正解データとの誤差　：　0.0973\n",
      "\n",
      "------------------------------------------------\n",
      "95epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0513\n",
      "\n",
      "検証用正解データとの誤差　：　0.0969\n",
      "\n",
      "------------------------------------------------\n",
      "96epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0504\n",
      "\n",
      "検証用正解データとの誤差　：　0.0965\n",
      "\n",
      "------------------------------------------------\n",
      "97epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0495\n",
      "\n",
      "検証用正解データとの誤差　：　0.0960\n",
      "\n",
      "------------------------------------------------\n",
      "98epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0486\n",
      "\n",
      "検証用正解データとの誤差　：　0.0956\n",
      "\n",
      "------------------------------------------------\n",
      "99epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0478\n",
      "\n",
      "検証用正解データとの誤差　：　0.0952\n",
      "\n",
      "------------------------------------------------\n",
      "100epoch目\n",
      "\n",
      "学習用正解データとの誤差　：　0.0470\n",
      "\n",
      "検証用正解データとの誤差　：　0.0949\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# インスタンス作成\n",
    "cls = ScratchSimpleNeuralNetrowkClassifier(lr=0.01,\\\n",
    "                                                                           sigma=0.01, \\\n",
    "                                                                           batch_size=10,\\\n",
    "                                                                           n_epochs=100,\\\n",
    "                                                                           n_features=784,\\\n",
    "                                                                           n_nodes1=400,\\\n",
    "                                                                           n_nodes2=200,\\\n",
    "                                                                           n_output=10,\\\n",
    "                                                                           activation='sig',\\\n",
    "                                                                           verbose=True)\n",
    "\n",
    "# cls.fit(X_train, y_train)\n",
    "cls.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.検証\n",
    "# 【問題2】学習曲線のプロット\n",
    "学習曲線をプロットしてください。\n",
    "\n",
    "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。trainデータとvalデータに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考察\n",
    "### 学習曲線がエポック数ごとに低下していることを確認し、正常に学習出来ていることを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】指標値の算出\n",
    "分類に関する指標値で精度を確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータにて予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cls.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータの正解データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス名を格納するリストの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class0',\n",
       " 'class1',\n",
       " 'class2',\n",
       " 'class3',\n",
       " 'class4',\n",
       " 'class5',\n",
       " 'class6',\n",
       " 'class7',\n",
       " 'class8',\n",
       " 'class9']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = []\n",
    "for i in range(10):\n",
    "    target_names.append('class' + str(i))\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指標値の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.91      0.91      0.91       980\n",
      "      class1       0.94      0.93      0.94      1135\n",
      "      class2       0.88      0.82      0.85      1032\n",
      "      class3       0.86      0.79      0.82      1010\n",
      "      class4       0.80      0.82      0.81       982\n",
      "      class5       0.72      0.73      0.72       892\n",
      "      class6       0.88      0.92      0.90       958\n",
      "      class7       0.83      0.88      0.86      1028\n",
      "      class8       0.73      0.78      0.75       974\n",
      "      class9       0.77      0.73      0.75      1009\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考察\n",
    "### Precision Recall F1 それぞれの指標値で最低でも70%以上となっており、高い精度で予測できていることを確認\n",
    "\n",
    " ### 値が低いクラスについては学習データのクラスごとの分布が影響している可能性あり"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sprint10-dl-scratch-neural-network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
