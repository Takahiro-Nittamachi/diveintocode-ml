{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.この課題の目的\n",
    "スクラッチを通してSVMを理解する\n",
    "線形モデルと異なる手法に触れる\n",
    "以下の要件をすべて満たしていた場合、合格とします。\n",
    "\n",
    "※Jupyter Notebookを使い課題に沿った検証や説明ができている。\n",
    "\n",
    "# 2.スクラッチによる実装\n",
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "SVMは分類と回帰双方に使用できますが、分類のみを扱います。SVMで重要な要素としてカーネルがありますが、まずは線形カーネルを作成します。他のカーネルの作成はアドバンス課題とします。また、SVMにはハードマージン、ソフトマージンという考え方がありますが、より単純なハードマージンを扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】SVM分類器のクラスを作成する\n",
    "SVM分類器のクラスを作成し、Sprint0で作成した分類のパイプラインに組み込んでください。\n",
    "\n",
    "クラスの基本構造はSprint3の線形回帰を参考にし、名前はScratchSVMClassifierとしてください。\n",
    "\n",
    "メソッドやパラメータなどはscikit-learnを参考にしてください。\n",
    "\n",
    "sklearn.svm.SVC — scikit-learn 0.20.2 documentation\n",
    "\n",
    "検証段階ではJupyter Notebook上で書いていき、最終的にはpyファイルにモジュールとしてまとめてください。\n",
    "\n",
    "scikit-learnにおけるパラメータについて\n",
    "\n",
    "scikit-learnの実装はソフトマージンSVMになっています。ハードマージンSVMを再現するには、パラメータCをC=1e10のように非常に大きな値を設定します。（無限大に向けてCを大きくするほどハードマージンSVMに近づきます）\n",
    "\n",
    "また、線形カーネルをscikit-learnで使う場合はkernel=\"linear\"と指定します。デフォルトではkernel=\"rbf\"になっており、多項式カーネルと呼ばれるものになっています。\n",
    "\n",
    "## ラグランジュの未定乗数法による最急降下\n",
    "SVMの最適化問題は、ラグランジュの未定乗数法により解くことができます。サンプル数分のラグランジュ乗数 \n",
    "λ\n",
    " を用意して、以下の式により更新していきます。\n",
    " \n",
    " $$\\lambda_i^{new} = \\lambda_i + \\alpha(1 - \\sum_{j=1}^{n}{\\lambda_j y_i y_j k(x_i, x_j)})$$\n",
    " \n",
    "ここで$k(x_i, x_j)$はカーネル関数です。線形カーネルの場合は次のようになります。他のカーネル関数にも対応できるように、この部分はメソッド化しておきましょう。\n",
    "$$k(x_i, x_j) = x_{i}^{T} x_j$$\n",
    "\n",
    "\n",
    "条件として、更新毎に$\\lambda_i >= 0$を満たす必要があります。満たさない場合は $\\lambda_i = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス作成時に使用するクラス\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 前処理に使用するクラス\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 評価指標のクラス\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 決定領域を描画する際にしようするクラス\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# 実行時間の計測に使用するクラス\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データを分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScratchSVMClassifierクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSVMClassifier():\n",
    "    \"\"\"\n",
    "    SVMのスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    lag_th : int\n",
    "        ラグランジュ乗数の更新を停止する個数(サポートベクトルがこの個数以下となれば、ラグランジュ乗数の更新を停止する)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.lagrang_ : 次の形のndarray, shape (n_features,)\n",
    "      ラグランジュ乗数\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr):\n",
    "        self.iter = num_iter # \n",
    "        self.lr = lr\n",
    "        self.lagrang = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        入力データを読み込み、サポートベクトルを決定する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            学習データ\n",
    "        y : ndarray\n",
    "            学習データ\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        インスタンス変数の初期化 (複数回fitメソッドを実行した際に、過去のインスタンス変数のデータが残らない様にする)\n",
    "        \"\"\"\n",
    "        self.lagrang = None # ラグランジュ乗数の初期化(fitメソッドを実行する為に)\n",
    "        \n",
    "        \"\"\"\n",
    "        学習データに対しての処理\n",
    "        \"\"\"\n",
    "        # 入力データをnumpy配列に変換\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # 入力データが１次元か判別\n",
    "        # １次元の場合→1次元追加し２次元のnumpy配列とする\n",
    "        if X.ndim == 1:\n",
    "            X = X[:, np.newaxis]\n",
    "        \n",
    "        if y.ndim==1:\n",
    "            y = y[:, np.newaxis]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "            \n",
    "        \"\"\"    \n",
    "        ラグランジュ乗数の更新\n",
    "        \"\"\"\n",
    "        self._gradient_descent(X, y)\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        \"\"\"\n",
    "        入力値のデータを求めた分類境界線に代入しラベルを予測する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習データ\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        prediction_result: int\n",
    "            予測結果　\n",
    "        \"\"\"\n",
    "        # サポートベクタのインデックスを取得\n",
    "        index = np.where(self.lagrang > 0)[0]\n",
    "        \n",
    "        # 予測\n",
    "        predict = np.sum(self.lagrang[index] * self.y[index] * self._linear_kernel(X, self.X[index]).T, axis=0)\n",
    "\n",
    "        #　値が0より大きい値かで分類する\n",
    "        predict = np.where(predict > 0, 1, -1)\n",
    "        \n",
    "        return predict\n",
    "\n",
    "\n",
    "    def _linear_kernel(self, X_i, X_j):\n",
    "        \"\"\"\n",
    "        線型カーネル関数を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_i : ndarray\n",
    "            特徴量データ\n",
    "        X_j : ndarray\n",
    "            特徴量データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "            カーネル関数の計算結果を格納したnumpy配列\n",
    "        \"\"\"\n",
    "        \n",
    "        return X_i @ X_j.T\n",
    "    \n",
    "    \n",
    "    def _gradient_descent(self, X, y):\n",
    "        \"\"\"\n",
    "        ラグランジュ乗数を最適化する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習データ\n",
    "        y : 次の形のndarray, shape (n_samples, 1)\n",
    "            \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        \n",
    "        # ラグランジュ乗数を格納するインスタンス変数self.lagrangeのshapeを(n_sample, 1)に変更\n",
    "        self.lagrang=np.random.rand(len(X)).reshape(-1,1) \n",
    "        \n",
    "        # sum.iter回、繰り返す\n",
    "        for it in range(self.iter):\n",
    "            # 総和計算の値を格納するリストを初期作成\n",
    "            sum_list = []\n",
    "            \n",
    "            # 入力データのサンプル数繰り返す\n",
    "            for i in range(len(X)):\n",
    "                # ラグランジュ乗数の変化量を計算しリストに格納\n",
    "                sum_list.append(np.sum(self.lagrang * y[i] * y * (self._linear_kernel(X, X[i].reshape(1,-1)))))\n",
    "\n",
    "            # 計算結果をnumpy配列に変換\n",
    "            sum_np = np.array(sum_list).reshape(-1,1)\n",
    "\n",
    "            # ラグランジュ乗数を更新\n",
    "            self.lagrang = self.lagrang + self.lr * (1 - sum_np)\n",
    "\n",
    "        \n",
    "        # ラグランジュ乗数の値が指定の値より小さいならばゼロとする\n",
    "        self.lagrang = np.where(self.lagrang > 1e-5, self.lagrang, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動作検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1 = ScratchSVMClassifier(num_iter=3000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "cls1.fit(X_train, y_train)\n",
    "y_pred1 = cls1.predict(X_test)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】指標値の算出\n",
    "分類に関する指標値で精度を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score = {}\\n'.format(accuracy_score(y_test, y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 1', 'class -1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       1.00      1.00      1.00        53\n",
      "    class -1       1.00      1.00      1.00        47\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】決定領域の可視化\n",
    "2値分類のデータセットに対して決定領域を可視化してください。\n",
    "\n",
    "これまで使用してきた関数に、サポートベクターを色を変えて表示する機能を加えてください。\n",
    "\n",
    "特にSprint0で作成したシンプルデータセット1に対して以下のように分類ができるかを検証してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 今回は2クラスの分類の為、2種類のマーカと色を用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ('s', 'x')\n",
    "cmap = ListedColormap(('red', 'blue'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの最小値と最大値を確認し、メッシュデータを0.01刻みで作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min, x1_max = X_test[:, 0].min()-1, X_test[:, 0].max()+1\n",
    "x2_min, x2_max = X_test[:, 1].min()-1, X_test[:, 1].max()+1\n",
    "x1_mesh, x2_mesh = np.meshgrid(np.arange(x1_min, x1_max, 0.01),\n",
    "                                   np.arange(x2_min, x2_max, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メッシュデータに対して作成したモデルで分類を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = cls1.predict(np.array([x1_mesh.ravel(), x2_mesh.ravel()]).T)\n",
    "z = z.reshape(x1_mesh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定領域を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.contourf(x1_mesh, x2_mesh, z, alpha=0.4, cmap=cmap)\n",
    "plt.xlim(x1_mesh.min(), x1_mesh.max())\n",
    "plt.ylim(x2_mesh.min(), x2_mesh.max())\n",
    "\n",
    "for idx, cl in enumerate(np.unique(y_test)):\n",
    "    plt.scatter(x=X_test[y_test == cl, 0],\n",
    "                y=X_test[y_test == cl, 1],\n",
    "                alpha=0.6,\n",
    "                c=cmap(idx),\n",
    "                edgecolors='black',\n",
    "                marker=markers[idx],\n",
    "                label=cl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】時間の計測\n",
    "SVMの学習には時間がかかるため、効率的な実装が望まれます。事前学習期間に行なったように、時間を計測して改善していきましょう。特に \n",
    "λ\n",
    " の更新部分は繰り返し処理が多いため、効率的なコードを目指してください。\n",
    "\n",
    "雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# t0 = time.time()\n",
    "# # 何らかの処理\n",
    "# t1 = time.time()\n",
    "# print('time : {}s'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修正前の学習開始〜予測終了までの実行時間時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修正前の学習開始〜予測終了までの実行時間 : 13.767158031463623s\n"
     ]
    }
   ],
   "source": [
    "print('修正前の学習開始〜予測終了までの実行時間 : {}s'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>結果→分類性能は変わらずに実行時間が<font color=\"Red\">約14秒短縮</font></u>\n",
    "## 以下より詳細を記載する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行時間の短縮方法\n",
    "- ラグランジュ乗数の更新を繰り返し、<u>ラグランジュ乗数の平均値の変化量が閾値以下となればラグランジュ乗数の更新を停止する</u>。\n",
    "- ラグランジュ乗数の更新を停止する閾値については、問題1にて最終的に100以下のサポートベクトルを使用して分類を行なっていた為、今回はその倍の<u>サポートベクトル200個あたりの時のラグランジュ乗数の平均値の差である0.02を使用</u>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修正後のScratchSVMClassifier_r2クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSVMClassifier_r2():\n",
    "    \n",
    "    \"\"\"\n",
    "    SVMのスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    lag_th : int\n",
    "        ラグランジュ乗数の更新を停止する個数(サポートベクトルがこの個数以下となれば、ラグランジュ乗数の更新を停止する)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.lagrang_ : 次の形のndarray, shape (n_features,)\n",
    "      ラグランジュ乗数\n",
    "    self.th : float\n",
    "      ラグランジュ乗数の更新を続けるかを判断する閾値\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, num_iter, lr, th):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        # 損失を記録する配列を用意\n",
    "        self.lagrang = None\n",
    "        self.th = th\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        入力データを読み込み、サポートベクトルを決定する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            学習データ\n",
    "        y : ndarray\n",
    "            学習データ\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        インスタンス変数の初期化 (複数回fitメソッドを実行した際に、過去のインスタンス変数のデータが残らない様にする)\n",
    "        \"\"\"\n",
    "        self.lagrang = None # ラグランジュ乗数の初期化(fitメソッドを実行する為に)\n",
    "        \n",
    "        \"\"\"\n",
    "        学習データに対しての処理\n",
    "        \"\"\"\n",
    "        # 入力データをnumpy配列に変換\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # 入力データが１次元か判別\n",
    "        # １次元の場合→1次元追加し２次元のnumpy配列とする\n",
    "        if X.ndim == 1:\n",
    "            X = X[:, np.newaxis]\n",
    "        \n",
    "        if y.ndim==1:\n",
    "            y = y[:, np.newaxis]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        \"\"\"    \n",
    "        ラグランジュ乗数の更新\n",
    "        \"\"\"\n",
    "        self._gradient_descent(X, y)\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        \"\"\"\n",
    "        入力値のデータを求めた分類境界線に代入しラベルを予測する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習データ\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        prediction_result: int\n",
    "            予測結果　\n",
    "        \"\"\"\n",
    "        # サポートベクタのインデックスを取得\n",
    "        index = np.where(self.lagrang > 0)[0]\n",
    "        \n",
    "        # 予測\n",
    "        predict = np.sum(self.lagrang[index] * self.y[index] * self._linear_kernel(X, self.X[index]).T, axis=0)\n",
    "\n",
    "        # 　値が0より大きい値かで分類する\n",
    "        predict = np.where(predict > 0, 1, -1)\n",
    "        \n",
    "        return predict\n",
    "    \n",
    "\n",
    "    def _linear_kernel(self, X_i, X_j):\n",
    "        \n",
    "        \"\"\"\n",
    "        線型カーネル関数を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_i : ndarray\n",
    "            特徴量データ\n",
    "        X_j : ndarray\n",
    "            特徴量データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "            カーネル関数の計算結果を格納したnumpy配列\n",
    "        \"\"\"\n",
    "        \n",
    "        return X_i @ X_j.T\n",
    "\n",
    "    \n",
    "    def _gradient_descent(self, X, y):\n",
    "        \"\"\"\n",
    "        ラグランジュ乗数を最適化する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習データ\n",
    "        y : 次の形のndarray, shape (n_samples, 1)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        \n",
    "        # ラグランジュ乗数を格納するインスタンス変数self.lagrangeのshapeを(n_sample, 1)に変更\n",
    "        self.lagrang=np.random.rand(len(X)).reshape(-1,1) \n",
    "        \n",
    "        # sum.iter回、繰り返す\n",
    "        for it in range(self.iter):\n",
    "            \n",
    "            # 総和計算の値を格納するリストを初期作成\n",
    "            sum_list = []\n",
    "            \n",
    "            # 入力データのサンプル数繰り返す\n",
    "            for i in range(len(X)):\n",
    "                \n",
    "                # ラグランジュ乗数の変化量を計算しリストに格納\n",
    "                sum_list.append(np.sum(self.lagrang * y[i] * y * (self._linear_kernel(X, X[i].reshape(1,-1)))))\n",
    "\n",
    "            # 計算結果をnumpy配列に変換\n",
    "            sum_np = np.array(sum_list).reshape(-1,1)\n",
    "\n",
    "            # ラグランジュ乗数を更新\n",
    "            new_lagrang = self.lagrang + self.lr * (1 - sum_np)\n",
    "            \n",
    "            print('現状のラグランジュ乗数の平均値 {}'.format(np.mean(self.lagrang)))\n",
    "            print('更新後のラグランジュ乗数の平均値{}'.format(np.mean(self.lagrang)))\n",
    "            print('平均値の差={}'.format((np.mean(self.lagrang) - np.mean(new_lagrang))))\n",
    "            \n",
    "            # 現在のラグランジュ乗数の平均値 − 更新後のラグランジュ乗数の平均値　の結果が閾値以下の場合、更新を停止\n",
    "            if (np.mean(self.lagrang) - np.mean(new_lagrang)) < self.th:\n",
    "                break\n",
    "            \n",
    "            # ラグランジュ乗数を更新\n",
    "            self.lagrang = new_lagrang\n",
    "        \n",
    "            # ラグランジュ乗数の値が指定の値より小さいならばゼロとする\n",
    "            self.lagrang = np.where(self.lagrang > 1e-5, self.lagrang, 0)\n",
    "            \n",
    "            print('ラグランジュ乗数の個数={}'.format(np.count_nonzero(self.lagrang)))\n",
    "            print('-----------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2 = ScratchSVMClassifier_r2(num_iter=3000, lr=0.0001, th=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行時間の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現状のラグランジュ乗数の平均値 0.508798129948338\n",
      "更新後のラグランジュ乗数の平均値0.508798129948338\n",
      "平均値の差=0.09239274059529728\n",
      "ラグランジュ乗数の個数=369\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.42031456748044016\n",
      "更新後のラグランジュ乗数の平均値0.42031456748044016\n",
      "平均値の差=0.07557234652096018\n",
      "ラグランジュ乗数の個数=336\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.35406300404047714\n",
      "更新後のラグランジュ乗数の平均値0.35406300404047714\n",
      "平均値の差=0.06305242988794763\n",
      "ラグランジュ乗数の個数=316\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.30354729798596997\n",
      "更新後のラグランジュ乗数の平均値0.30354729798596997\n",
      "平均値の差=0.05353659200819327\n",
      "ラグランジュ乗数の個数=295\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.2630880963245408\n",
      "更新後のラグランジュ乗数の平均値0.2630880963245408\n",
      "平均値の差=0.04592761066789133\n",
      "ラグランジュ乗数の個数=271\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.23143767959812003\n",
      "更新後のラグランジュ乗数の平均値0.23143767959812003\n",
      "平均値の差=0.040010372000494315\n",
      "ラグランジュ乗数の個数=256\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.20598990688451843\n",
      "更新後のラグランジュ乗数の平均値0.20598990688451843\n",
      "平均値の差=0.035301906062283867\n",
      "ラグランジュ乗数の個数=243\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.18478761701113677\n",
      "更新後のラグランジュ乗数の平均値0.18478761701113677\n",
      "平均値の差=0.03139425095502496\n",
      "ラグランジュ乗数の個数=231\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.1668752065117477\n",
      "更新後のラグランジュ乗数の平均値0.1668752065117477\n",
      "平均値の差=0.0281002292595621\n",
      "ラグランジュ乗数の個数=220\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.15176280368180778\n",
      "更新後のラグランジュ乗数の平均値0.15176280368180778\n",
      "平均値の差=0.025334699894624252\n",
      "ラグランジュ乗数の個数=205\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.1389938841127789\n",
      "更新後のラグランジュ乗数の平均値0.1389938841127789\n",
      "平均値の差=0.023017730880308285\n",
      "ラグランジュ乗数の個数=189\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.12835965976546732\n",
      "更新後のラグランジュ乗数の平均値0.12835965976546732\n",
      "平均値の差=0.021109789660250677\n",
      "ラグランジュ乗数の個数=183\n",
      "-----------------------------------------------------\n",
      "\n",
      "現状のラグランジュ乗数の平均値 0.11917472740334066\n",
      "更新後のラグランジュ乗数の平均値0.11917472740334066\n",
      "平均値の差=0.019472495388918418\n"
     ]
    }
   ],
   "source": [
    "t2 = time.time()\n",
    "cls2.fit(X_train, y_train)\n",
    "y_pred2 = cls2.predict(X_test)\n",
    "t3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 修正後の学習開始〜予測終了までの実行時間 : -0.08719587326049805s\n"
     ]
    }
   ],
   "source": [
    "print(' 修正後の学習開始〜予測終了までの実行時間 : {}s'.format(t2-t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行時間の差分を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.679962158203125"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t1 - t0) - (t3 - t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測精度比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修正前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score = {}\\n'.format(accuracy_score(y_test, y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 1', 'class -1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       1.00      1.00      1.00        53\n",
      "    class -1       1.00      1.00      1.00        47\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修正後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score = {}\\n'.format(accuracy_score(y_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 1', 'class -1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       1.00      1.00      1.00        53\n",
      "    class -1       1.00      1.00      1.00        47\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】ロジスティック回帰とSVM\n",
    "最終発表時に以下の内容についてディスカッションを行います。自分なりの意見を用意しておいてください。\n",
    "\n",
    "ロジスティック回帰とSVMは本質的に何が異なっているか\n",
    "\n",
    "## ①クラス分類を行う直線の求め方\n",
    "### ロジスティック回帰\n",
    "- 各特徴量との誤差の合計が最小となるような直線を引く。\n",
    "\n",
    "### SVM\n",
    "- それぞれのクラスのサポートベクトル(クラス分類を行う直線から最も近い特徴量)から最も距離(マージン)が大きくなる直線を引く。\n",
    "\n",
    "### 上記の違いによる各モデルの特徴\n",
    "- ロジスティック回帰は全ての特徴量に対して適した直線を引く為、外れ値などにも対応しようとして過学習の可能性が高い。\n",
    "- SVMは直線を引く為に考慮するのはサポートベクトルのみなので、外れ値の影響を受けない為、ロジスティック回帰と比較し過学習になりにくく、またマージン最大化の観点からより最適な分類を行うことが可能。\n",
    "\n",
    "## ②計算量の違い\n",
    "### ロジスティック回帰\n",
    "- インスタンス変数にて指定された回数分、勾配降下法によるパラメータ最適化を行う。\n",
    "- 計算回数→指定回数\n",
    "\n",
    "### SVM\n",
    "- サポートベクトルを決定する際にインスタンス変数にて指定された回数分、特徴量の２乗の計算を行い、ラグランジュ乗数を勾配降下法により更新し、計算終了時にラグランジュ乗数が0以上であった特徴量をサポートベクトルとする。\n",
    "- 計算回数→指定回数　×　サンプル数\n",
    "- \n",
    "### 上記の違いによる各モデルの特徴\n",
    "- ロジスティック回帰は指定された回数分のみ更新を行う為、予測精度をある程度犠牲にした場合は、更新回数を少なくし実行時間を減らすことが可能。\n",
    "- SVMは指定された回数　×　サンプル数の回数の計算を行う為、ロジスティック回帰と比較し計算量が多くなる。またその傾向は特徴量が多くなるほど顕著となる。その為、大容量のデータに対してはSVMモデルよりロジスティック回帰等の計算量の少ないモデルが適していると想定される。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
